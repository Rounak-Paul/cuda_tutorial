{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numba import cuda, float32\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def f(a, b, c):\n",
    "    pos = cuda.grid(1)\n",
    "    size = len(c)\n",
    "\n",
    "    if pos < size:\n",
    "        c[pos] = a[pos] + b[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "a = cuda.to_device(np.random.random(N))\n",
    "b = cuda.to_device(np.random.random(N))\n",
    "c = cuda.device_array_like(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forall() creates 1D grid for a given data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rouna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 98 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83095035, 0.96491347, 1.04135738, ..., 1.04118482, 1.02526096,\n",
       "       1.57020609])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.forall(len(a))(a, b, c)\n",
    "c.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83095035, 0.96491347, 1.04135738, ..., 1.04118482, 1.02526096,\n",
       "       1.57020609])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nthreads = 256\n",
    "nblocks = (len(a) // nthreads) + 1\n",
    "f[nblocks, nthreads](a, b, c)\n",
    "c.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform square matrix multiplication of C = A * B.\"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_h = np.arange(16).reshape([4, 4])\n",
    "y_h = np.ones([4, 4])\n",
    "z_h = np.zeros([4, 4])\n",
    "\n",
    "x_d = cuda.to_device(x_h)\n",
    "y_d = cuda.to_device(y_h)\n",
    "z_d = cuda.to_device(z_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "threadsperblock = (16, 16)\n",
    "blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
    "blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
    "blockspergrid = (blockspergrid_x, blockspergrid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rouna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "matmul[blockspergrid, threadsperblock](x_d, y_d, z_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  6.  6.  6.]\n",
      " [22. 22. 22. 22.]\n",
      " [38. 38. 38. 38.]\n",
      " [54. 54. 54. 54.]]\n"
     ]
    }
   ],
   "source": [
    "z_h = z_d.copy_to_host()\n",
    "print(z_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better Matrix Multiplication with Shared Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 32\n",
    "# threads per block\n",
    "\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = float32(0.)\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[ty, tx] = 0\n",
    "        sB[ty, tx] = 0\n",
    "        if y < A.shape[0] and (tx + i * TPB) < A.shape[1]:\n",
    "            sA[ty, tx] = A[y, tx + i * TPB]\n",
    "        if x < B.shape[1] and (ty + i * TPB) < B.shape[0]:\n",
    "            sB[ty, tx] = B[ty + i * TPB, x]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[ty, j] * sB[j, tx]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "    if y < C.shape[0] and x < C.shape[1]:\n",
    "        C[y, x] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_h = np.arange(128*128).reshape([128, 128])\n",
    "y_h = np.ones([128, 128])\n",
    "z_h = np.zeros([128, 128])\n",
    "\n",
    "x_d = cuda.to_device(x_h)\n",
    "y_d = cuda.to_device(y_h)\n",
    "z_d = cuda.to_device(z_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "threadsperblock = (TPB, TPB)\n",
    "blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
    "blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
    "blockspergrid = (blockspergrid_x, blockspergrid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rouna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.8 µs ± 309 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fast_matmul[blockspergrid, threadsperblock](x_d, y_d, z_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "z_h = z_d.copy_to_host()\n",
    "print(np.array_equal(z_h, x_h @ y_h))\n",
    "print(z_h.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
